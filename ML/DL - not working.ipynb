{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_data = pd.read_csv(\"Headline Vector.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075134</td>\n",
       "      <td>0.095032</td>\n",
       "      <td>-0.018885</td>\n",
       "      <td>0.180705</td>\n",
       "      <td>-0.102905</td>\n",
       "      <td>-0.075216</td>\n",
       "      <td>-0.176351</td>\n",
       "      <td>0.073771</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.183268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074249</td>\n",
       "      <td>-0.071838</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>-0.082937</td>\n",
       "      <td>0.046611</td>\n",
       "      <td>-0.056780</td>\n",
       "      <td>-0.076497</td>\n",
       "      <td>-0.079346</td>\n",
       "      <td>-0.049487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051987</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.053021</td>\n",
       "      <td>-0.163184</td>\n",
       "      <td>-0.148584</td>\n",
       "      <td>-0.017378</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>-0.025668</td>\n",
       "      <td>0.185156</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022070</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>-0.010620</td>\n",
       "      <td>-0.011060</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>-0.096582</td>\n",
       "      <td>-0.219296</td>\n",
       "      <td>-0.019531</td>\n",
       "      <td>-0.034570</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.053218</td>\n",
       "      <td>-0.006348</td>\n",
       "      <td>0.029297</td>\n",
       "      <td>-0.024763</td>\n",
       "      <td>-0.101214</td>\n",
       "      <td>0.095721</td>\n",
       "      <td>0.017421</td>\n",
       "      <td>0.055664</td>\n",
       "      <td>0.077637</td>\n",
       "      <td>0.046125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054060</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.039010</td>\n",
       "      <td>-0.062762</td>\n",
       "      <td>-0.095503</td>\n",
       "      <td>0.080261</td>\n",
       "      <td>-0.145647</td>\n",
       "      <td>-0.119036</td>\n",
       "      <td>0.022374</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004852</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>0.050012</td>\n",
       "      <td>0.075821</td>\n",
       "      <td>-0.047064</td>\n",
       "      <td>-0.048322</td>\n",
       "      <td>-0.006976</td>\n",
       "      <td>-0.144267</td>\n",
       "      <td>0.094218</td>\n",
       "      <td>0.108246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010461</td>\n",
       "      <td>-0.087931</td>\n",
       "      <td>0.035131</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>-0.154073</td>\n",
       "      <td>-0.074272</td>\n",
       "      <td>-0.091553</td>\n",
       "      <td>0.031362</td>\n",
       "      <td>0.067342</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.048256</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.097397</td>\n",
       "      <td>-0.040054</td>\n",
       "      <td>-0.036987</td>\n",
       "      <td>0.063026</td>\n",
       "      <td>-0.016579</td>\n",
       "      <td>0.097771</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087311</td>\n",
       "      <td>-0.083374</td>\n",
       "      <td>-0.000671</td>\n",
       "      <td>-0.103638</td>\n",
       "      <td>-0.021179</td>\n",
       "      <td>0.025879</td>\n",
       "      <td>-0.113892</td>\n",
       "      <td>0.025085</td>\n",
       "      <td>0.084534</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.075134  0.095032 -0.018885  0.180705 -0.102905 -0.075216 -0.176351   \n",
       "1  0.051987  0.013672  0.053021 -0.163184 -0.148584 -0.017378  0.009473   \n",
       "2 -0.053218 -0.006348  0.029297 -0.024763 -0.101214  0.095721  0.017421   \n",
       "3  0.004852 -0.001902  0.050012  0.075821 -0.047064 -0.048322 -0.006976   \n",
       "4  0.041016  0.048256  0.016785  0.097397 -0.040054 -0.036987  0.063026   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0  0.073771  0.096600  0.183268  ... -0.074249 -0.071838  0.033000 -0.082937   \n",
       "1 -0.025668  0.185156  0.015948  ...  0.022070  0.054199 -0.010620 -0.011060   \n",
       "2  0.055664  0.077637  0.046125  ...  0.054060  0.016811  0.039010 -0.062762   \n",
       "3 -0.144267  0.094218  0.108246  ... -0.010461 -0.087931  0.035131  0.014521   \n",
       "4 -0.016579  0.097771 -0.001984  ... -0.087311 -0.083374 -0.000671 -0.103638   \n",
       "\n",
       "        295       296       297       298       299  Fake  \n",
       "0  0.046611 -0.056780 -0.076497 -0.079346 -0.049487   1.0  \n",
       "1  0.019336 -0.096582 -0.219296 -0.019531 -0.034570   1.0  \n",
       "2 -0.095503  0.080261 -0.145647 -0.119036  0.022374   1.0  \n",
       "3 -0.154073 -0.074272 -0.091553  0.031362  0.067342   1.0  \n",
       "4 -0.021179  0.025879 -0.113892  0.025085  0.084534   1.0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_data_x =headline_data.drop(\"Fake\",axis=1)\n",
    "headline_data_y = headline_data[\"Fake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27259, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27259,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_data_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(headline_data_x, headline_data_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 301 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_data[headline_data.isnull().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "logits and labels must have the same shape ((?, 1) vs (?,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    970\u001b[0m         raise ValueError(\"Shapes %s and %s must have the same rank\" %\n\u001b[0;32m--> 971\u001b[0;31m                          (self, other))\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?,) and (?, 1) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m       \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?,) and (?, 1) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1846a13ec8da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-1846a13ec8da>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#     cost = tf.reduce_mean(prediction - y, name=\"cost\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#     optimizer = tf.train.AdamOptimizer().minimize(cost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\u001b[0;32m--> 168\u001b[0;31m                        (logits.get_shape(), labels.get_shape()))\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# The logistic loss formula from above is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: logits and labels must have the same shape ((?, 1) vs (?,))"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_nodes_hl1 = 300\n",
    "n_nodes_hl2 = 800\n",
    "n_nodes_hl3 = 800\n",
    "\n",
    "n_classes = 1\n",
    "batch_size = 100\n",
    "\n",
    "x = tf.placeholder('float', [None, 300])\n",
    "y = tf.placeholder('float', [None,])\n",
    "\n",
    "def neural_network_model(data):\n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([300, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes])),}\n",
    "\n",
    "\n",
    "    l1 = tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    output = tf.matmul(l3,output_layer['weights']) + output_layer['biases']\n",
    "    output = tf.nn.sigmoid(output)\n",
    "    return output\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = neural_network_model(x)\n",
    "#     cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
    "#     cost = tf.reduce_mean(prediction - y, name=\"cost\")\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=prediction)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1).minimize(cost)\n",
    "#     optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        epoch_loss = 0\n",
    "        for _ in range(10):\n",
    "            for i in range(900):\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={x: x_train[i:i+1], y: y_train[i:i+1]})\n",
    "                epoch_loss += c\n",
    "            print(epoch_loss)\n",
    "    \n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(headline)\n",
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
