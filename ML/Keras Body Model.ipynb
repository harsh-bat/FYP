{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Body Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_data = pd.read_csv(\"Body Vector.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>Fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050662</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>-0.030101</td>\n",
       "      <td>0.094391</td>\n",
       "      <td>-0.005058</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>-0.025954</td>\n",
       "      <td>0.103290</td>\n",
       "      <td>0.047973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055381</td>\n",
       "      <td>-0.074973</td>\n",
       "      <td>0.028826</td>\n",
       "      <td>0.023275</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>-0.050521</td>\n",
       "      <td>0.052581</td>\n",
       "      <td>-0.066990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.044124</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>-0.079713</td>\n",
       "      <td>-0.041712</td>\n",
       "      <td>-0.007093</td>\n",
       "      <td>-0.044684</td>\n",
       "      <td>0.118370</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>-0.007322</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>-0.039997</td>\n",
       "      <td>-0.085951</td>\n",
       "      <td>-0.020036</td>\n",
       "      <td>-0.007204</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007910</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>-0.055505</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>0.053245</td>\n",
       "      <td>-0.041645</td>\n",
       "      <td>0.109752</td>\n",
       "      <td>0.058014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>-0.013253</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>-0.017107</td>\n",
       "      <td>-0.031132</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>-0.079502</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>-0.012361</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043716</td>\n",
       "      <td>-0.007644</td>\n",
       "      <td>0.054707</td>\n",
       "      <td>0.102776</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>-0.017399</td>\n",
       "      <td>0.096088</td>\n",
       "      <td>-0.036231</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.103034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>-0.109193</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>-0.038788</td>\n",
       "      <td>-0.099942</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>-0.086343</td>\n",
       "      <td>-0.017817</td>\n",
       "      <td>0.046936</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.112088</td>\n",
       "      <td>-0.049997</td>\n",
       "      <td>-0.070807</td>\n",
       "      <td>0.067386</td>\n",
       "      <td>-0.013888</td>\n",
       "      <td>0.112655</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029751</td>\n",
       "      <td>-0.045796</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>-0.031584</td>\n",
       "      <td>0.077210</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>-0.023598</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>-0.041712</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.050662  0.031227 -0.030101  0.094391 -0.005058 -0.045496  0.008541   \n",
       "1  0.009187  0.034447  0.044124  0.011204 -0.079713 -0.041712 -0.007093   \n",
       "2 -0.007910  0.002882  0.005868  0.047244 -0.055505  0.019863  0.053245   \n",
       "3  0.043716 -0.007644  0.054707  0.102776  0.002611 -0.017399  0.096088   \n",
       "4  0.001495  0.016298  0.006372  0.112088 -0.049997 -0.070807  0.067386   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0 -0.025954  0.103290  0.047973  ...  0.055381 -0.074973  0.028826  0.023275   \n",
       "1 -0.044684  0.118370  0.050185  ...  0.001031 -0.014836  0.001227 -0.007322   \n",
       "2 -0.041645  0.109752  0.058014  ...  0.015184 -0.013253  0.021607 -0.017107   \n",
       "3 -0.036231  0.099773  0.103034  ...  0.004585 -0.109193 -0.035175 -0.038788   \n",
       "4 -0.013888  0.112655  0.003094  ...  0.029751 -0.045796  0.004718 -0.031584   \n",
       "\n",
       "        295       296       297       298       299  Fake  \n",
       "0  0.031859 -0.017179 -0.050521  0.052581 -0.066990   1.0  \n",
       "1  0.006936 -0.039997 -0.085951 -0.020036 -0.007204   1.0  \n",
       "2 -0.031132  0.006545 -0.079502 -0.001678 -0.012361   1.0  \n",
       "3 -0.099942 -0.001761 -0.086343 -0.017817  0.046936   1.0  \n",
       "4  0.077210  0.007886 -0.023598  0.035955 -0.041712   1.0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_data.dropna(inplace=True)\n",
    "X= body_data.drop(\"Fake\",axis=1)\n",
    "y= body_data[\"Fake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050662</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>-0.030101</td>\n",
       "      <td>0.094391</td>\n",
       "      <td>-0.005058</td>\n",
       "      <td>-0.045496</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>-0.025954</td>\n",
       "      <td>0.103290</td>\n",
       "      <td>0.047973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058377</td>\n",
       "      <td>0.055381</td>\n",
       "      <td>-0.074973</td>\n",
       "      <td>0.028826</td>\n",
       "      <td>0.023275</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>-0.017179</td>\n",
       "      <td>-0.050521</td>\n",
       "      <td>0.052581</td>\n",
       "      <td>-0.066990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.044124</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>-0.079713</td>\n",
       "      <td>-0.041712</td>\n",
       "      <td>-0.007093</td>\n",
       "      <td>-0.044684</td>\n",
       "      <td>0.118370</td>\n",
       "      <td>0.050185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049060</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>-0.007322</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>-0.039997</td>\n",
       "      <td>-0.085951</td>\n",
       "      <td>-0.020036</td>\n",
       "      <td>-0.007204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007910</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>-0.055505</td>\n",
       "      <td>0.019863</td>\n",
       "      <td>0.053245</td>\n",
       "      <td>-0.041645</td>\n",
       "      <td>0.109752</td>\n",
       "      <td>0.058014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033843</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>-0.013253</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>-0.017107</td>\n",
       "      <td>-0.031132</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>-0.079502</td>\n",
       "      <td>-0.001678</td>\n",
       "      <td>-0.012361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043716</td>\n",
       "      <td>-0.007644</td>\n",
       "      <td>0.054707</td>\n",
       "      <td>0.102776</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>-0.017399</td>\n",
       "      <td>0.096088</td>\n",
       "      <td>-0.036231</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.103034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012712</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>-0.109193</td>\n",
       "      <td>-0.035175</td>\n",
       "      <td>-0.038788</td>\n",
       "      <td>-0.099942</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>-0.086343</td>\n",
       "      <td>-0.017817</td>\n",
       "      <td>0.046936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.112088</td>\n",
       "      <td>-0.049997</td>\n",
       "      <td>-0.070807</td>\n",
       "      <td>0.067386</td>\n",
       "      <td>-0.013888</td>\n",
       "      <td>0.112655</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076776</td>\n",
       "      <td>0.029751</td>\n",
       "      <td>-0.045796</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>-0.031584</td>\n",
       "      <td>0.077210</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>-0.023598</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>-0.041712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.050662  0.031227 -0.030101  0.094391 -0.005058 -0.045496  0.008541   \n",
       "1  0.009187  0.034447  0.044124  0.011204 -0.079713 -0.041712 -0.007093   \n",
       "2 -0.007910  0.002882  0.005868  0.047244 -0.055505  0.019863  0.053245   \n",
       "3  0.043716 -0.007644  0.054707  0.102776  0.002611 -0.017399  0.096088   \n",
       "4  0.001495  0.016298  0.006372  0.112088 -0.049997 -0.070807  0.067386   \n",
       "\n",
       "          7         8         9  ...       290       291       292       293  \\\n",
       "0 -0.025954  0.103290  0.047973  ... -0.058377  0.055381 -0.074973  0.028826   \n",
       "1 -0.044684  0.118370  0.050185  ... -0.049060  0.001031 -0.014836  0.001227   \n",
       "2 -0.041645  0.109752  0.058014  ... -0.033843  0.015184 -0.013253  0.021607   \n",
       "3 -0.036231  0.099773  0.103034  ... -0.012712  0.004585 -0.109193 -0.035175   \n",
       "4 -0.013888  0.112655  0.003094  ... -0.076776  0.029751 -0.045796  0.004718   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.023275  0.031859 -0.017179 -0.050521  0.052581 -0.066990  \n",
       "1 -0.007322  0.006936 -0.039997 -0.085951 -0.020036 -0.007204  \n",
       "2 -0.017107 -0.031132  0.006545 -0.079502 -0.001678 -0.012361  \n",
       "3 -0.038788 -0.099942 -0.001761 -0.086343 -0.017817  0.046936  \n",
       "4 -0.031584  0.077210  0.007886 -0.023598  0.035955 -0.041712  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bat/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bat/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bat/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(500, activation='relu', kernel_initializer='random_normal', input_dim=300))\n",
    "classifier.add(Dense(400, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dense(300, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bat/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bat/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/bat/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bat/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/50\n",
      "26986/26986 [==============================] - 19s 692us/step - loss: 0.4853 - acc: 0.7710\n",
      "Epoch 2/50\n",
      "26986/26986 [==============================] - 18s 662us/step - loss: 0.4146 - acc: 0.8196\n",
      "Epoch 3/50\n",
      "26986/26986 [==============================] - 18s 661us/step - loss: 0.3828 - acc: 0.8373\n",
      "Epoch 4/50\n",
      "26986/26986 [==============================] - 18s 665us/step - loss: 0.3618 - acc: 0.8484\n",
      "Epoch 5/50\n",
      "26986/26986 [==============================] - 19s 717us/step - loss: 0.3456 - acc: 0.8544\n",
      "Epoch 6/50\n",
      "26986/26986 [==============================] - 16s 579us/step - loss: 0.3264 - acc: 0.8650\n",
      "Epoch 7/50\n",
      "26986/26986 [==============================] - 15s 565us/step - loss: 0.3159 - acc: 0.8700\n",
      "Epoch 8/50\n",
      "26986/26986 [==============================] - 17s 643us/step - loss: 0.3032 - acc: 0.8760\n",
      "Epoch 9/50\n",
      "26986/26986 [==============================] - 15s 559us/step - loss: 0.2927 - acc: 0.8802\n",
      "Epoch 10/50\n",
      "26986/26986 [==============================] - 15s 546us/step - loss: 0.2801 - acc: 0.8869\n",
      "Epoch 11/50\n",
      "26986/26986 [==============================] - 15s 546us/step - loss: 0.2728 - acc: 0.8893\n",
      "Epoch 12/50\n",
      "26986/26986 [==============================] - 15s 572us/step - loss: 0.2621 - acc: 0.8938\n",
      "Epoch 13/50\n",
      "26986/26986 [==============================] - 17s 636us/step - loss: 0.2532 - acc: 0.8995\n",
      "Epoch 14/50\n",
      "26986/26986 [==============================] - 15s 551us/step - loss: 0.2454 - acc: 0.9025\n",
      "Epoch 15/50\n",
      "26986/26986 [==============================] - 16s 592us/step - loss: 0.2392 - acc: 0.9053\n",
      "Epoch 16/50\n",
      "26986/26986 [==============================] - 16s 610us/step - loss: 0.2305 - acc: 0.9094\n",
      "Epoch 17/50\n",
      "26986/26986 [==============================] - 20s 750us/step - loss: 0.2199 - acc: 0.9140\n",
      "Epoch 18/50\n",
      "26986/26986 [==============================] - 16s 575us/step - loss: 0.2114 - acc: 0.9155\n",
      "Epoch 19/50\n",
      "26986/26986 [==============================] - 17s 613us/step - loss: 0.2043 - acc: 0.9208\n",
      "Epoch 20/50\n",
      "26986/26986 [==============================] - 16s 583us/step - loss: 0.1973 - acc: 0.9224\n",
      "Epoch 21/50\n",
      "26986/26986 [==============================] - 18s 654us/step - loss: 0.1919 - acc: 0.9244\n",
      "Epoch 22/50\n",
      "26986/26986 [==============================] - 15s 557us/step - loss: 0.1854 - acc: 0.9281\n",
      "Epoch 23/50\n",
      "26986/26986 [==============================] - 15s 540us/step - loss: 0.1817 - acc: 0.9282\n",
      "Epoch 24/50\n",
      "26986/26986 [==============================] - 15s 540us/step - loss: 0.1769 - acc: 0.9318\n",
      "Epoch 25/50\n",
      "26986/26986 [==============================] - 15s 538us/step - loss: 0.1684 - acc: 0.9359\n",
      "Epoch 26/50\n",
      "26986/26986 [==============================] - 15s 538us/step - loss: 0.1626 - acc: 0.9371\n",
      "Epoch 27/50\n",
      "26986/26986 [==============================] - 16s 585us/step - loss: 0.1569 - acc: 0.9390\n",
      "Epoch 28/50\n",
      "26986/26986 [==============================] - 16s 598us/step - loss: 0.1512 - acc: 0.9423\n",
      "Epoch 29/50\n",
      "26986/26986 [==============================] - 15s 549us/step - loss: 0.1452 - acc: 0.9420\n",
      "Epoch 30/50\n",
      "26986/26986 [==============================] - 15s 540us/step - loss: 0.1440 - acc: 0.9436\n",
      "Epoch 31/50\n",
      "26986/26986 [==============================] - 15s 545us/step - loss: 0.1372 - acc: 0.9485\n",
      "Epoch 32/50\n",
      "26986/26986 [==============================] - 15s 542us/step - loss: 0.1337 - acc: 0.9488\n",
      "Epoch 33/50\n",
      "26986/26986 [==============================] - 15s 543us/step - loss: 0.1273 - acc: 0.9508\n",
      "Epoch 34/50\n",
      "26986/26986 [==============================] - 15s 542us/step - loss: 0.1194 - acc: 0.9539\n",
      "Epoch 35/50\n",
      "26986/26986 [==============================] - 15s 542us/step - loss: 0.1203 - acc: 0.9545\n",
      "Epoch 36/50\n",
      "26986/26986 [==============================] - 15s 549us/step - loss: 0.1128 - acc: 0.9563\n",
      "Epoch 37/50\n",
      "26986/26986 [==============================] - 15s 541us/step - loss: 0.1131 - acc: 0.9558\n",
      "Epoch 38/50\n",
      "26986/26986 [==============================] - 15s 539us/step - loss: 0.1109 - acc: 0.9581\n",
      "Epoch 39/50\n",
      "26986/26986 [==============================] - 15s 540us/step - loss: 0.1044 - acc: 0.9597\n",
      "Epoch 40/50\n",
      "26986/26986 [==============================] - 15s 541us/step - loss: 0.0992 - acc: 0.9625\n",
      "Epoch 41/50\n",
      "26986/26986 [==============================] - 15s 540us/step - loss: 0.0958 - acc: 0.9633\n",
      "Epoch 42/50\n",
      "26986/26986 [==============================] - 15s 537us/step - loss: 0.0954 - acc: 0.9643\n",
      "Epoch 43/50\n",
      "26986/26986 [==============================] - 15s 539us/step - loss: 0.0930 - acc: 0.9648\n",
      "Epoch 44/50\n",
      "26986/26986 [==============================] - 15s 542us/step - loss: 0.0901 - acc: 0.9656\n",
      "Epoch 45/50\n",
      "26986/26986 [==============================] - 16s 579us/step - loss: 0.0863 - acc: 0.9687\n",
      "Epoch 46/50\n",
      "26986/26986 [==============================] - 15s 564us/step - loss: 0.0867 - acc: 0.9687\n",
      "Epoch 47/50\n",
      "26986/26986 [==============================] - 15s 541us/step - loss: 0.0834 - acc: 0.9702\n",
      "Epoch 48/50\n",
      "26986/26986 [==============================] - 15s 540us/step - loss: 0.0785 - acc: 0.9711\n",
      "Epoch 49/50\n",
      "26986/26986 [==============================] - 14s 537us/step - loss: 0.0758 - acc: 0.9708\n",
      "Epoch 50/50\n",
      "26986/26986 [==============================] - 15s 540us/step - loss: 0.0782 - acc: 0.9706\n"
     ]
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "history = classifier.fit(X_train,y_train, batch_size=10, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26986/26986 [==============================] - 1s 28us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.061246219179138514, 0.9772845178981694]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "y_pred =(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[128  22]\n",
      " [ 13 110]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717948717948718"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = classifier.to_json()\n",
    "with open(\"bodyModel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "classifier.save_weights(\"bodyModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
